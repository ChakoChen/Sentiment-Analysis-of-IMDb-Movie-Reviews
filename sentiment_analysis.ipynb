{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Overview \n",
    "\n",
    "For this analysis we’ll be using a dataset of 50,000 movie reviews \n",
    "taken from IMDb. The data was compiled by Andrew Maas and can be \n",
    "found here: IMDb Reviews (http://ai.stanford.edu/~amaas/data/sentiment/).\n",
    "\n",
    "The data is split evenly with 25k reviews intended for training and \n",
    "25k for testing your classifier. Moreover, each set has 12.5k \n",
    "positive and 12.5k negative reviews.\n",
    "\n",
    "IMDb lets users rate movies on a scale from 1 to 10. To label \n",
    "these reviews the curator of the data labeled anything with \n",
    "≤ 4 stars as negative and anything with ≥ 7 stars as positive. \n",
    "Reviews with 5 or 6 stars were left out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Read in the reviews\n",
    "reviews_train = []\n",
    "for line in open('../../data/aclImdb/movie_data/full_train.txt', 'r'):\n",
    "    reviews_train.append(line.strip())\n",
    "    \n",
    "reviews_test = []\n",
    "for line in open('../../data/aclImdb/movie_data/full_test.txt', 'r'):\n",
    "    reviews_test.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This isn't the comedic Robin Williams, nor is it the quirky/insane Robin Williams of recent thriller fame. This is a hybrid of the classic drama without over-dramatization, mixed with Robin's new love of the thriller. But this isn't a thriller, per se. This is more a mystery/suspense vehicle through which Williams attempts to locate a sick boy and his keeper.<br /><br />Also starring Sandra Oh and Rory Culkin, this Suspense Drama plays pretty much like a news report, until William's character gets close to achieving his goal.<br /><br />I must say that I was highly entertained, though this movie fails to teach, guide, inspect, or amuse. It felt more like I was watching a guy (Williams), as he was actually performing the actions, from a third person perspective. In other words, it felt real, and I was able to subscribe to the premise of the story.<br /><br />All in all, it's worth a watch, though it's definitely not Friday/Saturday night fare.<br /><br />It rates a 7.7/10 from...<br /><br />the Fiend :.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_train[5]  # reviews contain unwanted characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Clean and Preprocess--Tidy the reviews by getting rid of/replacing unwanted characters with space\n",
    "import re\n",
    "\n",
    "REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\d+)\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "NO_SPACE = \"\"\n",
    "SPACE = \" \"\n",
    "\n",
    "def preprocess_reviews(reviews):\n",
    "    reviews = [REPLACE_NO_SPACE.sub(NO_SPACE, line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(SPACE, line) for line in reviews]\n",
    "    return reviews\n",
    "\n",
    "reviews_train_clean = preprocess_reviews(reviews_train)\n",
    "reviews_test_clean = preprocess_reviews(reviews_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this isnt the comedic robin williams nor is it the quirky insane robin williams of recent thriller fame this is a hybrid of the classic drama without over dramatization mixed with robins new love of the thriller but this isnt a thriller per se this is more a mystery suspense vehicle through which williams attempts to locate a sick boy and his keeper also starring sandra oh and rory culkin this suspense drama plays pretty much like a news report until williams character gets close to achieving his goal i must say that i was highly entertained though this movie fails to teach guide inspect or amuse it felt more like i was watching a guy williams as he was actually performing the actions from a third person perspective in other words it felt real and i was able to subscribe to the premise of the story all in all its worth a watch though its definitely not friday saturday night fare it rates a   from the fiend '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_train_clean[5]  # reviews are clean now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Vectorization--convert each review to a numeric representation\n",
    "\"\"\"\n",
    "The simplest form of this is to create one very large matrix \n",
    "with one column for every unique word in your corpus \n",
    "(where the corpus is all 50k reviews in our case). \n",
    "Then we transform each review into one row containing 0s and 1s, \n",
    "where 1 means that the word in the corpus corresponding to \n",
    "that column appears in that review. That being said, \n",
    "each row of the matrix will be very sparse (mostly zeros). \n",
    "This process is also known as one hot encoding.\n",
    "\"\"\"\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = TfidfVectorizer(binary=True)  # gives better prediction results\n",
    "#cv = CountVectorizer(binary=True)\n",
    "cv.fit(reviews_train_clean)\n",
    "X = cv.transform(reviews_train_clean)\n",
    "X_test = cv.transform(reviews_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cchen/miniconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.83232\n",
      "Accuracy for C=0.05: 0.85088\n",
      "Accuracy for C=0.25: 0.87072\n",
      "Accuracy for C=0.5: 0.87952\n",
      "Accuracy for C=1: 0.88544\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Build Classifier\n",
    "\"\"\"\n",
    "Now that we’ve transformed our dataset into a format suitable for \n",
    "modeling we can start building a classifier. \n",
    "Logistic Regression is a good baseline model for us to use \n",
    "for several reasons: \n",
    "(1) They’re easy to interpret, \n",
    "(2) linear models tend to perform well on sparse datasets like this one, and \n",
    "(3) they learn very fast compared to other algorithms.\n",
    "\n",
    "To keep things simple I’m only going to worry about \n",
    "the hyperparameter C, which adjusts the regularization.\n",
    "\n",
    "Note: The targets/labels we use will be the same for training \n",
    "and testing because both datasets are structured the same, \n",
    "where the first 12.5k are positive and the last 12.5k are negative.\n",
    "\"\"\"\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "target = [1 if i < 12500 else 0 for i in range(25000)]\n",
    "\n",
    "# First, use a subset of the train set to get an optimal hyperparameter\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, target, train_size = 0.75)\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
    "    \n",
    "#     Accuracy for C=0.01: 0.87472\n",
    "#     Accuracy for C=0.05: 0.88368\n",
    "#     Accuracy for C=0.25: 0.88016\n",
    "#     Accuracy for C=0.5: 0.87808\n",
    "#     Accuracy for C=1: 0.87648\n",
    "\n",
    "#  The value of C that gives us the highest accuracy is 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.856\n"
     ]
    }
   ],
   "source": [
    "# Train final model\n",
    "\"\"\"\n",
    "Now that we’ve found the optimal value for C, we should train a model \n",
    "using the entire training set and evaluate our accuracy on the 25k \n",
    "test reviews.\n",
    "\"\"\"\n",
    "final_model = LogisticRegression(C=0.05)\n",
    "final_model.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final_model.predict(X_test)))\n",
    "# Final Accuracy: 0.88128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: LOVED IT! This movie was amazing. Top 10 this year.\n",
      "Probability of positive review: 0.7651982913550238\n",
      "Review: Total junk! I'll never watch a film by that director again, no matter how good the reviews.\n",
      "Probability of positive review: 0.21523347721452063\n"
     ]
    }
   ],
   "source": [
    "# Make some predictions\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def get_features(review):\n",
    "    return cv.transform([review])\n",
    "\n",
    "# Predict sentiment for a glowing review\n",
    "review1 = \"LOVED IT! This movie was amazing. Top 10 this year.\"\n",
    "review1_features = get_features(review1)\n",
    "print(\"Review:\", review1)\n",
    "print(\"Probability of positive review:\", final_model.predict_proba(review1_features)[0,1])\n",
    "\n",
    "# Predict sentiment for a poor review\n",
    "review2 = \"Total junk! I'll never watch a film by that director again, no matter how good the reviews.\"\n",
    "review2_features = get_features(review2)\n",
    "print(\"Review:\", review2)\n",
    "print(\"Probability of positive review:\", lr.predict_proba(review2_features)[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('great', 1.8840509214410224)\n",
      "('excellent', 1.3884072707342143)\n",
      "('best', 1.2961021967900876)\n",
      "('love', 1.1584900640211526)\n",
      "('wonderful', 1.1518504420439997)\n",
      "('bad', -2.3389314858564085)\n",
      "('worst', -2.2122343185011553)\n",
      "('waste', -1.5623682742489695)\n",
      "('awful', -1.4770778282885826)\n",
      "('no', -1.2354706007960563)\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "\"\"\"\n",
    "Let’s look at the 5 most discriminating words for both positive and \n",
    "negative reviews. We’ll do this by looking at the largest and \n",
    "smallest coefficients, respectively.\n",
    "\"\"\"\n",
    "feature_to_coef = {word: coef \n",
    "                   for word, coef in \n",
    "                   zip(cv.get_feature_names(), final_model.coef_[0])}\n",
    "\n",
    "# Sort dict by values: key=lambda kv: kv[1]\n",
    "for best_positive in sorted(\n",
    "    feature_to_coef.items(), key=lambda x: x[1],\n",
    "    reverse=True)[:5]:\n",
    "    print (best_positive)\n",
    "    \n",
    "#     ('excellent', 0.9288812418118644)\n",
    "#     ('perfect', 0.7934641227980576)\n",
    "#     ('great', 0.675040909917553)\n",
    "#     ('amazing', 0.6160398142631545)\n",
    "#     ('superb', 0.6063967799425831)\n",
    "    \n",
    "for best_negative in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1])[:5]:\n",
    "    print (best_negative)\n",
    "    \n",
    "#     ('worst', -1.367978497228895)\n",
    "#     ('waste', -1.1684451288279047)\n",
    "#     ('awful', -1.0277001734353677)\n",
    "#     ('poorly', -0.8748317895742782)\n",
    "#     ('boring', -0.8587249740682945)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
